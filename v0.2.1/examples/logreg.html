<!DOCTYPE html><HTML lang="en"><head><meta charset="UTF-8"/><meta content="width=device-width, initial-scale=1.0" name="viewport"/><title>
Simple MNIST · Flux
    </title><script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-36890222-9', 'auto');
ga('send', 'pageview');

    </script><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.5.0/styles/default.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Ubuntu+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/><script>
documenterBaseURL=".."
    </script><script data-main="../assets/documenter.js" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js"></script><script src="../../versions.js"></script><link href="../../flux.css" rel="stylesheet" type="text/css"/><script data-outdated-warner="">function maybeAddWarning () {
    const head = document.getElementsByTagName('head')[0];

    // Add a noindex meta tag (unless one exists) so that search engines don't index this version of the docs.
    if (document.body.querySelector('meta[name="robots"]') === null) {
        const meta = document.createElement('meta');
        meta.name = 'robots';
        meta.content = 'noindex';

        head.appendChild(meta);
    };

    // Add a stylesheet to avoid inline styling
    const style = document.createElement('style');
    style.type = 'text/css';
    style.appendChild(document.createTextNode('.outdated-warning-overlay {  position: fixed;  top: 0;  left: 0;  right: 0;  box-shadow: 0 0 10px rgba(0, 0, 0, 0.3);  z-index: 999;  background-color: #ffaba7;  color: rgba(0, 0, 0, 0.7);  border-bottom: 3px solid #da0b00;  padding: 10px 35px;  text-align: center;  font-size: 15px; }  .outdated-warning-overlay .outdated-warning-closer {    position: absolute;    top: calc(50% - 10px);    right: 18px;    cursor: pointer;    width: 12px; }  .outdated-warning-overlay a {    color: #2e63b8; }    .outdated-warning-overlay a:hover {      color: #363636; }'));
    head.appendChild(style);

    const div = document.createElement('div');
    div.classList.add('outdated-warning-overlay');
    const closer = document.createElement('div');
    closer.classList.add('outdated-warning-closer');

    // Icon by font-awesome (license: https://fontawesome.com/license, link: https://fontawesome.com/icons/times?style=solid)
    closer.innerHTML = '<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="times" class="svg-inline--fa fa-times fa-w-11" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 352 512"><path fill="currentColor" d="M242.72 256l100.07-100.07c12.28-12.28 12.28-32.19 0-44.48l-22.24-22.24c-12.28-12.28-32.19-12.28-44.48 0L176 189.28 75.93 89.21c-12.28-12.28-32.19-12.28-44.48 0L9.21 111.45c-12.28 12.28-12.28 32.19 0 44.48L109.28 256 9.21 356.07c-12.28 12.28-12.28 32.19 0 44.48l22.24 22.24c12.28 12.28 32.2 12.28 44.48 0L176 322.72l100.07 100.07c12.28 12.28 32.2 12.28 44.48 0l22.24-22.24c12.28-12.28 12.28-32.19 0-44.48L242.72 256z"></path></svg>';
    closer.addEventListener('click', function () {
        document.body.removeChild(div);
    });
    let href = '/stable';
    if (window.documenterBaseURL) {
        href = window.documenterBaseURL + '/../stable';
    }
    div.innerHTML = 'This documentation is not for the latest version. <br> <a href="' + href + '">Go to the latest documentation</a>.';
    div.appendChild(closer);
    document.body.appendChild(div);
};

if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', maybeAddWarning);
} else {
    maybeAddWarning();
};
</script></head><body><nav class="toc"><h1>
Flux
      </h1><form action="../search.html" class="search"><select id="version-selector" onchange="window.location.href=this.value"><option disabled="disabled" selected="selected" value="#">
Version
          </option></select><input id="search-query" name="q" placeholder="Search docs" type="text"/></form><ul><li><a class="toctext" href="../index.html">
Home
          </a></li><li><span class="toctext">
Building Models
          </span><ul><li><a class="toctext" href="../models/basics.html">
Model Building Basics
              </a></li><li><a class="toctext" href="../models/templates.html">
Model Templates
              </a></li><li><a class="toctext" href="../models/recurrent.html">
Recurrence
              </a></li><li><a class="toctext" href="../models/debugging.html">
Debugging
              </a></li></ul></li><li><span class="toctext">
Other APIs
          </span><ul><li><a class="toctext" href="../apis/batching.html">
Batching
              </a></li><li><a class="toctext" href="../apis/backends.html">
Backends
              </a></li><li><a class="toctext" href="../apis/storage.html">
Storing Models
              </a></li></ul></li><li><span class="toctext">
In Action
          </span><ul><li class="current"><a class="toctext" href="logreg.html">
Simple MNIST
              </a><ul class="internal"></ul></li><li><a class="toctext" href="char-rnn.html">
Char RNN
              </a></li></ul></li><li><a class="toctext" href="../contributing.html">
Contributing &amp; Help
          </a></li><li><a class="toctext" href="../internals.html">
Internals
          </a></li></ul></nav><article id="docs"><header><nav><ul><li>
In Action
            </li><li><a href="logreg.html">
Simple MNIST
              </a></li></ul><a class="edit-page" href="https://github.com/MikeInnes/Flux.jl/tree/7a85eff370b7c68d587b49699fa3f71e44993397/docs/src/examples/logreg.md"><span class="fa">

            </span>
 Edit on GitHub
          </a></nav><hr/></header><h1><a class="nav-anchor" href="#Recognising-MNIST-Digits-1" id="Recognising-MNIST-Digits-1">
Recognising MNIST Digits
        </a></h1><p>
This walkthrough example will take you through writing a multi-layer perceptron that classifies MNIST digits with high accuracy.
      </p><p>
First, we load the data using the MNIST package:
      </p><pre><code class="language-julia">using Flux, MNIST
using Flux: accuracy

data = [(trainfeatures(i), onehot(trainlabel(i), 0:9)) for i = 1:60_000]
train = data[1:50_000]
test = data[50_001:60_000]</code></pre><p>
The only Flux-specific function here is 
<code>onehot</code>
, which takes a class label and turns it into a one-hot-encoded vector that we can use for training. For example:
      </p><pre><code class="language-julia">julia&gt; onehot(:b, [:a, :b, :c])
3-element Array{Int64,1}:
 0
 1
 0</code></pre><p>
Otherwise, the format of the data is simple enough, it's just a list of tuples from input to output. For example:
      </p><pre><code class="language-julia">julia&gt; data[1]
([0.0,0.0,0.0, … 0.0,0.0,0.0],[0,0,0,0,0,1,0,0,0,0])</code></pre><p><code>data[1][1]</code>
 is a 
<code>28*28 == 784</code>
 length vector (mostly zeros due to the black background) and 
<code>data[1][2]</code>
 is its classification.
      </p><p>
Now we define our model, which will simply be a function from one to the other.
      </p><pre><code class="language-julia">m = @Chain(
  Input(784),
  Affine(128), relu,
  Affine( 64), relu,
  Affine( 10), softmax)

model = mxnet(m) # Convert to MXNet</code></pre><p>
We can try this out on our data already:
      </p><pre><code class="language-julia">julia&gt; model(tobatch(data[1][1]))
10-element Array{Float64,1}:
 0.10614  
 0.0850447
 0.101474
 ...</code></pre><p>
The model gives a probability of about 0.1 to each class – which is a way of saying, "I have no idea". This isn't too surprising as we haven't shown it any data yet. This is easy to fix:
      </p><pre><code class="language-julia">Flux.train!(model, train, η = 1e-3,
            cb = [()-&gt;@show accuracy(m, test)])</code></pre><p>
The training step takes about 5 minutes (to make it faster we can do smarter things like batching). If you run this code in Juno, you'll see a progress meter, which you can hover over to see the remaining computation time.
      </p><p>
Towards the end of the training process, Flux will have reported that the accuracy of the model is now about 90%. We can try it on our data again:
      </p><pre><code class="language-julia">10-element Array{Float32,1}:
 ...
 5.11423f-7
 0.9354     
 3.1033f-5  
 0.000127077
 ...</code></pre><p>
Notice the class at 93%, suggesting our model is very confident about this image. We can use 
<code>onecold</code>
 to compare the true and predicted classes:
      </p><pre><code class="language-julia">julia&gt; onecold(data[1][2], 0:9)
5

julia&gt; onecold(model(tobatch(data[1][1])), 0:9)
5</code></pre><p>
Success!
      </p><footer><hr/><a class="previous" href="../apis/storage.html"><span class="direction">
Previous
          </span><span class="title">
Storing Models
          </span></a><a class="next" href="char-rnn.html"><span class="direction">
Next
          </span><span class="title">
Char RNN
          </span></a></footer></article></body></HTML>