<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Performance Tips · Flux</title><meta name="title" content="Performance Tips · Flux"/><meta property="og:title" content="Performance Tips · Flux"/><meta property="twitter:title" content="Performance Tips · Flux"/><meta name="description" content="Documentation for Flux."/><meta property="og:description" content="Documentation for Flux."/><meta property="twitter:description" content="Documentation for Flux."/><script async src="https://www.googletagmanager.com/gtag/js?id=UA-36890222-9"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-36890222-9', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/flux.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="Flux logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="Flux logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Welcome</a></li><li><span class="tocitem">Guide</span><ul><li><a class="tocitem" href="../models/quickstart/">Quick Start</a></li><li><a class="tocitem" href="../models/overview/">Fitting a Line</a></li><li><a class="tocitem" href="../models/basics/">Gradients and Layers</a></li><li><a class="tocitem" href="../models/custom_layers/">Custom Layers</a></li><li><a class="tocitem" href="../training/training/">Training</a></li><li><a class="tocitem" href="../models/recurrence/">Recurrence</a></li><li><a class="tocitem" href="../gpu/">GPU Support</a></li><li><a class="tocitem" href="../saving/">Saving &amp; Loading</a></li><li class="is-active"><a class="tocitem" href>Performance Tips</a><ul class="internal"><li><a class="tocitem" href="#Don&#39;t-use-more-precision-than-you-need"><span>Don&#39;t use more precision than you need</span></a></li><li><a class="tocitem" href="#Preserve-inputs&#39;-types"><span>Preserve inputs&#39; types</span></a></li><li><a class="tocitem" href="#Evaluate-batches-as-matrices-of-features"><span>Evaluate batches as matrices of features</span></a></li><li><a class="tocitem" href="#Be-aware-of-GPU-memory-inefficiencies"><span>Be aware of GPU memory inefficiencies</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../../ecosystem/">Ecosystem</a></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../../reference/models/layers/">Built-in Layers</a></li><li><a class="tocitem" href="../../reference/models/activation/">Activation Functions</a></li><li><a class="tocitem" href="../../reference/utilities/">Weight Initialisation</a></li><li><a class="tocitem" href="../../reference/models/losses/">Loss Functions</a></li><li><a class="tocitem" href="../../reference/training/reference/">Training API</a></li><li><a class="tocitem" href="../../reference/training/optimisers/">Optimisation Rules</a></li><li><a class="tocitem" href="../../reference/outputsize/">Shape Inference</a></li><li><a class="tocitem" href="../../reference/destructure/">Flat vs. Nested</a></li><li><a class="tocitem" href="../../reference/training/callbacks/">Callback Helpers</a></li><li><a class="tocitem" href="../../reference/training/zygote/">Gradients – Zygote.jl</a></li><li><a class="tocitem" href="../../reference/data/mlutils/">Batching Data – MLUtils.jl</a></li><li><a class="tocitem" href="../../reference/data/onehot/">OneHotArrays.jl</a></li><li><a class="tocitem" href="../../reference/models/nnlib/">Low-level Operations – NNlib.jl</a></li><li><a class="tocitem" href="../../reference/models/functors/">Nested Structures – Functors.jl</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/linear_regression/">Linear Regression</a></li><li><a class="tocitem" href="../../tutorials/logistic_regression/">Logistic Regression</a></li><li><a class="tocitem" href="../../tutorials/model_zoo/">Model Zoo</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Guide</a></li><li class="is-active"><a href>Performance Tips</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Performance Tips</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/FluxML/Flux.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/FluxML/Flux.jl/blob/master/docs/src/guide/performance.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="man-performance-tips"><a class="docs-heading-anchor" href="#man-performance-tips">Performance Tips</a><a id="man-performance-tips-1"></a><a class="docs-heading-anchor-permalink" href="#man-performance-tips" title="Permalink"></a></h1><p>All the usual <a href="https://docs.julialang.org/en/v1/manual/performance-tips/">Julia performance tips apply</a>. As always <a href="https://docs.julialang.org/en/v1/manual/profile/#Profiling-1">profiling your code</a> is generally a useful way of finding bottlenecks. Below follow some Flux specific tips/reminders.</p><h2 id="Don&#39;t-use-more-precision-than-you-need"><a class="docs-heading-anchor" href="#Don&#39;t-use-more-precision-than-you-need">Don&#39;t use more precision than you need</a><a id="Don&#39;t-use-more-precision-than-you-need-1"></a><a class="docs-heading-anchor-permalink" href="#Don&#39;t-use-more-precision-than-you-need" title="Permalink"></a></h2><p>Flux works great with all kinds of number types. But often you do not need to be working with say <code>Float64</code> (let alone <code>BigFloat</code>). Switching to <code>Float32</code> can give you a significant speed up, not because the operations are faster, but because the memory usage is halved. Which means allocations occur much faster. And you use less memory.</p><h2 id="Preserve-inputs&#39;-types"><a class="docs-heading-anchor" href="#Preserve-inputs&#39;-types">Preserve inputs&#39; types</a><a id="Preserve-inputs&#39;-types-1"></a><a class="docs-heading-anchor-permalink" href="#Preserve-inputs&#39;-types" title="Permalink"></a></h2><p>Not only should your activation and loss functions be <a href="https://docs.julialang.org/en/v1/manual/performance-tips/#Write-%22type-stable%22-functions-1">type-stable</a>, they should also preserve the type of their inputs.</p><p>A very artificial example using an activation function like</p><pre><code class="language-julia hljs">my_tanh(x) = Float64(tanh(x))</code></pre><p>will result in performance on <code>Float32</code> input orders of magnitude slower than the normal <code>tanh</code> would, because it results in having to use slow mixed type multiplication in the dense layers. Similar situations can occur in the loss function during backpropagation.</p><p>Which means if you change your data say from <code>Float64</code> to <code>Float32</code> (which should give a speedup: see above), you will see a large slow-down.</p><p>This can occur sneakily, because you can cause type-promotion by interacting with a numeric literals. E.g. the following will have run into the same problem as above:</p><pre><code class="language-julia hljs">leaky_tanh(x) = 0.01*x + tanh(x)</code></pre><p>While one could change the activation function (e.g. to use <code>0.01f0*x</code>), the idiomatic (and safe way)  to avoid type casts whenever inputs changes is to use <code>oftype</code>:</p><pre><code class="language-julia hljs">leaky_tanh(x) = oftype(x/1, 0.01)*x + tanh(x)</code></pre><h2 id="Evaluate-batches-as-matrices-of-features"><a class="docs-heading-anchor" href="#Evaluate-batches-as-matrices-of-features">Evaluate batches as matrices of features</a><a id="Evaluate-batches-as-matrices-of-features-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluate-batches-as-matrices-of-features" title="Permalink"></a></h2><p>While it can sometimes be tempting to process your observations (feature vectors) one at a time e.g.</p><pre><code class="language-julia hljs">function loss_total(xs::AbstractVector{&lt;:Vector}, ys::AbstractVector{&lt;:Vector})
    sum(zip(xs, ys)) do (x, y_target)
        y_pred = model(x)  # evaluate the model
        return loss(y_pred, y_target)
    end
end</code></pre><p>It is much faster to concatenate them into a matrix, as this will hit BLAS matrix-matrix multiplication, which is much faster than the equivalent sequence of matrix-vector multiplications. The improvement is enough that it is worthwhile allocating new memory to store them contiguously.</p><pre><code class="language-julia hljs">x_batch = reduce(hcat, xs)
y_batch = reduce(hcat, ys)
...
function loss_total(x_batch::Matrix, y_batch::Matrix)
    y_preds = model(x_batch)
    sum(loss.(y_preds, y_batch))
end</code></pre><p>When doing this kind of concatenation use <code>reduce(hcat, xs)</code> rather than <code>hcat(xs...)</code>. This will avoid the splatting penalty, and will hit the optimised <code>reduce</code> method.</p><h2 id="Be-aware-of-GPU-memory-inefficiencies"><a class="docs-heading-anchor" href="#Be-aware-of-GPU-memory-inefficiencies">Be aware of GPU memory inefficiencies</a><a id="Be-aware-of-GPU-memory-inefficiencies-1"></a><a class="docs-heading-anchor-permalink" href="#Be-aware-of-GPU-memory-inefficiencies" title="Permalink"></a></h2><p>Currently, GPU memory is not handled as well as system memory. If your training loop is allocating significantly on the GPU, you can quickly fill your GPU memory and the piecemeal reclamation and shuffling of data between GPU and system memory can become extremely slow. If profiling shows that a significant portion of time is spent in the <code>gpu</code> function and your data sizes are not large, this may be the cause. Running an incremental garbage collection manually (<code>GC.gc(false)</code>) at regular intervals can keep your GPU memory free and responsive. See other tips for CUDA memory management <a href="https://cuda.juliagpu.org/stable/usage/memory/">here</a>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../saving/">« Saving &amp; Loading</a><a class="docs-footer-nextpage" href="../../ecosystem/">Ecosystem »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Saturday 12 October 2024 14:11">Saturday 12 October 2024</span>. Using Julia version 1.11.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
