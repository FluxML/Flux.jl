<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Saving &amp; Loading · Flux</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-36890222-9', 'auto');
ga('send', 'pageview', {'page': location.pathname + location.search + location.hash});
</script><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/flux.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="Flux logo"/></a><div class="docs-package-name"><span class="docs-autofit">Flux</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Building Models</span><ul><li><a class="tocitem" href="../models/overview/">Overview</a></li><li><a class="tocitem" href="../models/basics/">Basics</a></li><li><a class="tocitem" href="../models/recurrence/">Recurrence</a></li><li><a class="tocitem" href="../models/layers/">Model Reference</a></li><li><a class="tocitem" href="../models/losses/">Loss Functions</a></li><li><a class="tocitem" href="../models/regularisation/">Regularisation</a></li><li><a class="tocitem" href="../models/advanced/">Advanced Model Building</a></li><li><a class="tocitem" href="../models/nnlib/">NNlib</a></li><li><a class="tocitem" href="../models/functors/">Functors</a></li></ul></li><li><span class="tocitem">Handling Data</span><ul><li><a class="tocitem" href="../data/onehot/">One-Hot Encoding</a></li><li><a class="tocitem" href="../data/mlutils/">MLUtils</a></li></ul></li><li><span class="tocitem">Training Models</span><ul><li><a class="tocitem" href="../training/optimisers/">Optimisers</a></li><li><a class="tocitem" href="../training/training/">Training</a></li></ul></li><li><a class="tocitem" href="../gpu/">GPU Support</a></li><li class="is-active"><a class="tocitem" href>Saving &amp; Loading</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#some-predefined-model"><span>some predefined model</span></a></li><li class="toplevel"><a class="tocitem" href="#load-one-model-into-another"><span>load one model into another</span></a></li><li class="toplevel"><a class="tocitem" href="#Show-loss"><span>Show loss</span></a></li></ul></li><li><a class="tocitem" href="../ecosystem/">The Julia Ecosystem</a></li><li><a class="tocitem" href="../utilities/">Utility Functions</a></li><li><a class="tocitem" href="../performance/">Performance Tips</a></li><li><a class="tocitem" href="../datasets/">Datasets</a></li><li><a class="tocitem" href="../community/">Community</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Saving &amp; Loading</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Saving &amp; Loading</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/FluxML/Flux.jl/blob/master/docs/src/saving.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Saving-and-Loading-Models"><a class="docs-heading-anchor" href="#Saving-and-Loading-Models">Saving and Loading Models</a><a id="Saving-and-Loading-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Saving-and-Loading-Models" title="Permalink"></a></h1><p>You may wish to save models so that they can be loaded and run in a later session. The easiest way to do this is via <a href="https://github.com/JuliaIO/BSON.jl">BSON.jl</a>.</p><p>Save a model:</p><pre><code class="language-julia">julia&gt; using Flux

julia&gt; model = Chain(Dense(10, 5, NNlib.relu), Dense(5, 2), NNlib.softmax)
Chain(
  Dense(10 =&gt; 5, relu),                 # 55 parameters
  Dense(5 =&gt; 2),                        # 12 parameters
  NNlib.softmax,
)                   # Total: 4 arrays, 67 parameters, 524 bytes.

julia&gt; using BSON: @save

julia&gt; @save &quot;mymodel.bson&quot; model</code></pre><p>Load it again:</p><pre><code class="language-julia">julia&gt; using Flux

julia&gt; using BSON: @load

julia&gt; @load &quot;mymodel.bson&quot; model

julia&gt; model
Chain(
  Dense(10 =&gt; 5, relu),                 # 55 parameters
  Dense(5 =&gt; 2),                        # 12 parameters
  NNlib.softmax,
)                   # Total: 4 arrays, 67 parameters, 524 bytes.</code></pre><p>Models are just normal Julia structs, so it&#39;s fine to use any Julia storage format for this purpose. BSON.jl is particularly well supported and most likely to be forwards compatible (that is, models saved now will load in future versions of Flux).</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>If a saved model&#39;s parameters are stored on the GPU, the model will not load later on if there is no GPU support available. It&#39;s best to <a href="../gpu/">move your model to the CPU</a> with <code>cpu(model)</code> before saving it.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Previous versions of Flux suggested saving only the model weights using <code>@save &quot;mymodel.bson&quot; params(model)</code>. This is no longer recommended and even strongly discouraged. Saving models this way will only store the trainable parameters which will result in incorrect behavior for layers like <code>BatchNorm</code>.</p></div></div><pre><code class="language-Julia">julia&gt; using Flux

julia&gt; model = Chain(Dense(10 =&gt; 5,relu),Dense(5 =&gt; 2),softmax)
Chain(Dense(10, 5, NNlib.relu), Dense(5, 2), NNlib.softmax)

julia&gt; weights = Flux.params(model);

Loading the model as shown above will return a new model with the stored parameters.
But sometimes you already have a model, and you want to load stored parameters into it.
This can be done as
</code></pre><p>julia using Flux: loadmodel! using BSON: @load</p><h1 id="some-predefined-model"><a class="docs-heading-anchor" href="#some-predefined-model">some predefined model</a><a id="some-predefined-model-1"></a><a class="docs-heading-anchor-permalink" href="#some-predefined-model" title="Permalink"></a></h1><p>model = Chain(Dense(10 =&gt; 5, relu), Dense(5 =&gt; 2), softmax)</p><h1 id="load-one-model-into-another"><a class="docs-heading-anchor" href="#load-one-model-into-another">load one model into another</a><a id="load-one-model-into-another-1"></a><a class="docs-heading-anchor-permalink" href="#load-one-model-into-another" title="Permalink"></a></h1><p>model = loadmodel!(model, @load(&quot;mymodel.bson&quot;))</p><pre><code class="language-none">
This ensures that the model loaded from `&quot;mymodel.bson&quot;` matches the structure of `model`. [`Flux.loadmodel!`](@ref) is also convenient for copying parameters between models in memory.
</code></pre><p>@docs Flux.loadmodel!</p><pre><code class="language-none">
## Checkpointing

In longer training runs it&#39;s a good idea to periodically save your model, so that you can resume if training is interrupted (for example, if there&#39;s a power cut). You can do this by saving the model in the [callback provided to `train!`](training/training.md).
</code></pre><p>julia using Flux: throttle using BSON: @save</p><p>m = Chain(Dense(10 =&gt; 5, relu), Dense(5 =&gt; 2), softmax)</p><p>evalcb = throttle(30) do</p><h1 id="Show-loss"><a class="docs-heading-anchor" href="#Show-loss">Show loss</a><a id="Show-loss-1"></a><a class="docs-heading-anchor-permalink" href="#Show-loss" title="Permalink"></a></h1><p>@save &quot;model-checkpoint.bson&quot; model end</p><pre><code class="language-none">
This will update the `&quot;model-checkpoint.bson&quot;` file every thirty seconds.

You can get more advanced by saving a series of models throughout training, for example
</code></pre><p>julia @save &quot;model-now().bson&quot; model</p><pre><code class="language-none">
will produce a series of models like `&quot;model-2018-03-06T02:57:10.41.bson&quot;`. You
could also store the current test set loss, so that it&#39;s easy to (for example)
revert to an older copy of the model if it starts to overfit.
</code></pre><p>julia @save &quot;model-now().bson&quot; model loss = testloss()</p><pre><code class="language-none">
Note that to resume a model&#39;s training, you might need to restore other stateful parts of your training loop. Possible examples are stateful optimizers (which usually utilize an `IdDict` to store their state), and the randomness used to partition the original data into the training and validation sets.

You can store the optimiser state alongside the model, to resume training
exactly where you left off. BSON is smart enough to [cache values](https://github.com/JuliaIO/BSON.jl/blob/v0.3.4/src/write.jl#L71) and insert links when saving, but only if it knows everything to be saved up front. Thus models and optimizers must be saved together to have the latter work after restoring.
</code></pre><p>julia opt = ADAM() @save &quot;model-now().bson&quot; model opt ```</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gpu/">« GPU Support</a><a class="docs-footer-nextpage" href="../ecosystem/">The Julia Ecosystem »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 7 April 2022 09:04">Thursday 7 April 2022</span>. Using Julia version 1.6.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
