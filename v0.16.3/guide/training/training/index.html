<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Training · Flux</title><meta name="title" content="Training · Flux"/><meta property="og:title" content="Training · Flux"/><meta property="twitter:title" content="Training · Flux"/><meta name="description" content="Documentation for Flux."/><meta property="og:description" content="Documentation for Flux."/><meta property="twitter:description" content="Documentation for Flux."/><script async src="https://www.googletagmanager.com/gtag/js?id=UA-36890222-9"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-36890222-9', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/flux.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img class="docs-light-only" src="../../../assets/logo.png" alt="Flux logo"/><img class="docs-dark-only" src="../../../assets/logo-dark.png" alt="Flux logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Welcome</a></li><li><span class="tocitem">Guide</span><ul><li><a class="tocitem" href="../../models/quickstart/">Quick Start</a></li><li><a class="tocitem" href="../../models/overview/">Fitting a Line</a></li><li><a class="tocitem" href="../../models/basics/">Gradients and Layers</a></li><li class="is-active"><a class="tocitem" href>Training</a><ul class="internal"><li><a class="tocitem" href="#Model-Gradients"><span>Model Gradients</span></a></li><li><a class="tocitem" href="#Loss-Functions"><span>Loss Functions</span></a></li><li><a class="tocitem" href="#Optimisation-Rules"><span>Optimisation Rules</span></a></li><li><a class="tocitem" href="#Datasets-and-Batches"><span>Datasets &amp; Batches</span></a></li><li><a class="tocitem" href="#Training-Loops"><span>Training Loops</span></a></li><li><a class="tocitem" href="#Regularisation"><span>Regularisation</span></a></li><li><a class="tocitem" href="#Learning-Rate-Schedules"><span>Learning Rate Schedules</span></a></li><li><a class="tocitem" href="#Scheduling-Optimisers"><span>Scheduling Optimisers</span></a></li><li><a class="tocitem" href="#Freezing-layer-parameters"><span>Freezing layer parameters</span></a></li></ul></li><li><a class="tocitem" href="../../models/recurrence/">Recurrence</a></li><li><a class="tocitem" href="../../gpu/">GPU Support</a></li><li><a class="tocitem" href="../../saving/">Saving &amp; Loading</a></li><li><a class="tocitem" href="../../performance/">Performance Tips</a></li></ul></li><li><a class="tocitem" href="../../../ecosystem/">Ecosystem</a></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../../../reference/models/layers/">Built-in Layers</a></li><li><a class="tocitem" href="../../../reference/models/activation/">Activation Functions</a></li><li><a class="tocitem" href="../../../reference/utilities/">Weight Initialisation</a></li><li><a class="tocitem" href="../../../reference/models/losses/">Loss Functions</a></li><li><a class="tocitem" href="../../../reference/training/reference/">Training API</a></li><li><a class="tocitem" href="../../../reference/training/optimisers/">Optimisation Rules</a></li><li><a class="tocitem" href="../../../reference/outputsize/">Shape Inference</a></li><li><a class="tocitem" href="../../../reference/destructure/">Flat vs. Nested</a></li><li><a class="tocitem" href="../../../reference/training/callbacks/">Callback Helpers</a></li><li><a class="tocitem" href="../../../reference/training/zygote/">Gradients – Zygote.jl</a></li><li><a class="tocitem" href="../../../reference/training/enzyme/">Gradients – Enzyme.jl</a></li><li><a class="tocitem" href="../../../reference/data/mldatadevices/">Transfer Data to GPU – MLDataDevices.jl</a></li><li><a class="tocitem" href="../../../reference/data/mlutils/">Batching Data – MLUtils.jl</a></li><li><a class="tocitem" href="../../../reference/data/onehot/">OneHotArrays.jl</a></li><li><a class="tocitem" href="../../../reference/models/nnlib/">Low-level Operations – NNlib.jl</a></li><li><a class="tocitem" href="../../../reference/models/functors/">Nested Structures – Functors.jl</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../../tutorials/linear_regression/">Linear Regression</a></li><li><a class="tocitem" href="../../../tutorials/logistic_regression/">Logistic Regression</a></li><li><a class="tocitem" href="../../../tutorials/custom_layers/">Custom Layers</a></li><li><a class="tocitem" href="../../../tutorials/model_zoo/">Model Zoo</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Guide</a></li><li class="is-active"><a href>Training</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Training</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/FluxML/Flux.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/FluxML/Flux.jl/blob/master/docs/src/guide/training/training.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="man-training"><a class="docs-heading-anchor" href="#man-training">Training a Flux Model</a><a id="man-training-1"></a><a class="docs-heading-anchor-permalink" href="#man-training" title="Permalink"></a></h1><p>Training refers to the process of slowly adjusting the parameters of a model to make it work better. Besides the model itself, we will need three things:</p><ul><li>An <em>objective function</em> that evaluates how well a model is doing on some input.</li><li>An <em>optimisation rule</em> which describes how the model&#39;s parameters should be adjusted.</li><li>Some <em>training data</em> to use as the input during this process.</li></ul><p>Usually the training data is some collection of examples (or batches of examples) which are handled one-by-one. One <em>epoch</em> of training means that each example is used once, something like this:</p><pre><code class="language-julia hljs"># Initialise the optimiser for this model:
opt_state = Flux.setup(rule, model)

for data in train_set
  # Unpack this element (for supervised training):
  input, label = data

  # Calculate the gradient of the objective
  # with respect to the parameters within the model:
  grads = Flux.gradient(model) do m
      result = m(input)
      loss(result, label)
  end

  # Update the parameters so as to reduce the objective,
  # according the chosen optimisation rule:
  Flux.update!(opt_state, model, grads[1])
end</code></pre><p>This loop can also be written using the function <a href="../../../reference/training/enzyme/#Flux.Train.train!-Tuple{Any, EnzymeCore.Duplicated, Any, Any}"><code>train!</code></a>, but it&#39;s helpful to understand the pieces first:</p><pre><code class="language-julia hljs">train!(model, train_set, opt_state) do m, x, y
  loss(m(x), y)
end</code></pre><h2 id="Model-Gradients"><a class="docs-heading-anchor" href="#Model-Gradients">Model Gradients</a><a id="Model-Gradients-1"></a><a class="docs-heading-anchor-permalink" href="#Model-Gradients" title="Permalink"></a></h2><p>Fist recall from the section on <a href="../../models/basics/#man-taking-gradients">taking gradients</a> that <code>Flux.gradient(f, a, b)</code> always calls <code>f(a, b)</code>, and returns a tuple <code>(∂f_∂a, ∂f_∂b)</code>. In the code above, the function <code>f</code> passed to <code>gradient</code> is an anonymous function with one argument, created by the <code>do</code> block, hence  <code>grads</code> is a tuple with one element. Instead of a <code>do</code> block, we could have written:</p><pre><code class="language-julia hljs">grads = Flux.gradient(m -&gt; loss(m(input), label), model)</code></pre><p>Since the model is some nested set of layers, <code>grads[1]</code> is a similarly nested set of <code>NamedTuple</code>s, ultimately containing gradient components. If (for example)  <code>θ = model.layers[1].weight[2,3]</code> is one scalar parameter, an entry in a matrix of weights, then the derivative of the loss with respect to it is <code>∂f_∂θ = grads[1].layers[1].weight[2,3]</code>.</p><p>It is important that the execution of the model takes place inside the call to <code>gradient</code>, in order for the influence of the model&#39;s parameters to be observed by Zygote.</p><p>It is also important that every <code>update!</code> step receives a newly computed gradient, as it will change whenever the model&#39;s parameters are changed, and for each new data point.</p><h2 id="Loss-Functions"><a class="docs-heading-anchor" href="#Loss-Functions">Loss Functions</a><a id="Loss-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Loss-Functions" title="Permalink"></a></h2><p>The objective function must return a number representing how far the model is from the desired result. This is termed the <em>loss</em> of the model.</p><p>This number can be produced by any ordinary Julia code, but this must be executed within the call to <code>gradient</code>. For instance, we could define a function</p><pre><code class="language-julia hljs">loss(y_hat, y) = sum((y_hat .- y).^2)</code></pre><p>or write this directly inside the <code>do</code> block above. Many commonly used functions, like <a href="../../../reference/models/losses/#Flux.Losses.mse"><code>mse</code></a> for mean-squared error or <a href="../../../reference/models/losses/#Flux.Losses.crossentropy"><code>crossentropy</code></a> for cross-entropy loss, are available from the <a href="../../../reference/models/losses/"><code>Flux.Losses</code></a> module.</p><h2 id="Optimisation-Rules"><a class="docs-heading-anchor" href="#Optimisation-Rules">Optimisation Rules</a><a id="Optimisation-Rules-1"></a><a class="docs-heading-anchor-permalink" href="#Optimisation-Rules" title="Permalink"></a></h2><p>The simplest kind of optimisation using the gradient is termed <em>gradient descent</em> (or sometimes <em>stochastic gradient descent</em> when, as here, it is not applied to the entire dataset at once).</p><p>Gradient descent needs a <em>learning rate</em> which is a small number describing how fast to walk downhill, usually written as the Greek letter &quot;eta&quot;, <code>η</code>. This is often described as a <em>hyperparameter</em>, to distinguish it from the parameters which are being updated <code>θ = θ - η * ∂loss_∂θ</code>. We want to update all the parameters in the model, like this:</p><pre><code class="language-julia hljs">η = 0.01   # learning rate

# For each parameter array, update
# according to the corresponding gradient:
fmap(model, grads[1]) do p, g
  p .= p .- η .* g
end</code></pre><p>A slightly more refined version of this loop to update all the parameters is wrapped up as a function <a href="../../../reference/training/reference/#Optimisers.update!"><code>update!</code></a><code>(opt_state, model, grads[1])</code>. And the learning rate is the only thing stored in the <a href="../../../reference/training/optimisers/#Optimisers.Descent"><code>Descent</code></a> struct.</p><p>However, there are many other optimisation rules, which adjust the step size and direction in various clever ways. Most require some memory of the gradients from earlier steps, rather than always walking straight downhill – <a href="../../../reference/training/optimisers/#Optimisers.Momentum"><code>Momentum</code></a> is the simplest. The function <a href="../../../reference/training/reference/#Flux.Train.setup"><code>setup</code></a> creates the necessary storage for this, for a particular model. It should be called once, before training, and returns a tree-like object which is the first argument of <code>update!</code>. Like this:</p><pre><code class="language-julia hljs"># Initialise momentum 
opt_state = Flux.setup(Momentum(0.01, 0.9), model)

for data in train_set
  grads = [...]

  # Update both model parameters and optimiser state:
  Flux.update!(opt_state, model, grads[1])
end</code></pre><p>Many commonly-used optimisation rules, such as <a href="../../../reference/training/optimisers/#Optimisers.Adam"><code>Adam</code></a>, are built-in. These are listed on the <a href="../../../reference/training/optimisers/#man-optimisers">optimisers</a> page.</p><div class="admonition is-compat"><header class="admonition-header">Implicit-style optimiser state</header><div class="admonition-body"><p>This <code>setup</code> makes another tree-like structure. Old versions of Flux did not do this, and instead stored a dictionary-like structure within the optimiser <code>Adam(0.001)</code>. This was initialised on first use of the version of <code>update!</code> for &quot;implicit&quot; parameters.</p></div></div><h2 id="Datasets-and-Batches"><a class="docs-heading-anchor" href="#Datasets-and-Batches">Datasets &amp; Batches</a><a id="Datasets-and-Batches-1"></a><a class="docs-heading-anchor-permalink" href="#Datasets-and-Batches" title="Permalink"></a></h2><p>The loop above iterates through <code>train_set</code>, expecting at each step a tuple <code>(input, label)</code>. The very simplest such object is a vector of tuples, such as this:</p><pre><code class="language-julia hljs">x = randn(28, 28)
y = rand(10)
data = [(x, y)]</code></pre><p>or <code>data = [(x, y), (x, y), (x, y)]</code> for the same values three times.</p><p>Very often, the initial data is large arrays which you need to slice into examples. To produce one iterator of pairs <code>(x, y)</code>, you might want <code>zip</code>:</p><pre><code class="language-julia hljs">X = rand(28, 28, 60_000);  # many images, each 28 × 28
Y = rand(10, 60_000)
data = zip(eachslice(X; dims=3), eachcol(Y))

first(data) isa Tuple{AbstractMatrix, AbstractVector}  # true</code></pre><p>Here each iteration will use one matrix <code>x</code> (an image, perhaps) and one vector <code>y</code>. It is very common to instead train on <em>batches</em> of such inputs (or <em>mini-batches</em>, the two words mean the same thing) both for efficiency and for better results. This can be easily done using the <a href="../../../reference/data/mlutils/#MLUtils.DataLoader"><code>DataLoader</code></a>:</p><pre><code class="language-julia hljs">data = Flux.DataLoader((X, Y), batchsize=32)

x1, y1 = first(data)
size(x1) == (28, 28, 32)
length(data) == 1875 === 60_000 ÷ 32</code></pre><p>Flux&#39;s layers are set up to accept such a batch of input data, and the convolutional layers such as <a href="../../../reference/models/layers/#Flux.Conv"><code>Conv</code></a> require it. The batch index is always the last dimension.</p><h2 id="Training-Loops"><a class="docs-heading-anchor" href="#Training-Loops">Training Loops</a><a id="Training-Loops-1"></a><a class="docs-heading-anchor-permalink" href="#Training-Loops" title="Permalink"></a></h2><p>Simple training loops like the one above can be written compactly using the <a href="../../../reference/training/enzyme/#Flux.Train.train!-Tuple{Any, EnzymeCore.Duplicated, Any, Any}"><code>train!</code></a> function. Including <code>setup</code>, this reads:</p><pre><code class="language-julia hljs">opt_state = Flux.setup(Adam(), model)

for epoch in 1:100
  Flux.train!(model, train_set, opt_state) do m, x, y
    loss(m(x), y)
  end
end</code></pre><p>Or explicitly writing the anonymous function which this <code>do</code> block creates, <code>train!((m,x,y) -&gt; loss(m(x),y), model, train_set, opt_state)</code> is exactly equivalent.</p><p>Real training loops often need more flexibility, and the best way to do this is just to write the loop. This is ordinary Julia code, without any need to work through some callback API. Here is an example, in which it may be helpful to note:</p><ul><li>The function <a href="../../../reference/training/zygote/#Zygote.withgradient-Tuple{Any, Vararg{Any}}"><code>withgradient</code></a> is like <code>gradient</code> but also returns the value of the function, for logging or diagnostic use.</li><li>Logging or printing is best done outside of the <code>gradient</code> call, as there is no need to differentiate these commands.</li><li>To use <code>result</code> for logging purposes, you could change the <code>do</code> block to end with  <code>return my_loss(result, label), result</code>, i.e. make the function passed to <code>withgradient</code> return a tuple. The first element is always the loss.</li><li>Julia&#39;s <code>break</code> and <code>continue</code> keywords let you exit from parts of the loop.</li></ul><pre><code class="language-julia hljs">opt_state = Flux.setup(Adam(), model)

my_log = []
for epoch in 1:100
  losses = Float32[]
  for (i, data) in enumerate(train_set)
    input, label = data

    val, grads = Flux.withgradient(model) do m
      # Any code inside here is differentiated.
      # Evaluation of the model and loss must be inside!
      result = m(input)
      my_loss(result, label)
    end

    # Save the loss from the forward pass. (Done outside of gradient.)
    push!(losses, val)

    # Detect loss of Inf or NaN. Print a warning, and then skip update!
    if !isfinite(val)
      @warn &quot;loss is $val on item $i&quot; epoch
      continue
    end

    Flux.update!(opt_state, model, grads[1])
  end

  # Compute some accuracy, and save details as a NamedTuple
  acc = my_accuracy(model, train_set)
  push!(my_log, (; acc, losses))

  # Stop training when some criterion is reached
  if  acc &gt; 0.95
    println(&quot;stopping after $epoch epochs&quot;)
    break
  end
end</code></pre><h2 id="Regularisation"><a class="docs-heading-anchor" href="#Regularisation">Regularisation</a><a id="Regularisation-1"></a><a class="docs-heading-anchor-permalink" href="#Regularisation" title="Permalink"></a></h2><p>The term <em>regularisation</em> covers a wide variety of techniques aiming to improve the result of training. This is often done to avoid overfitting.</p><p>Some of these can be implemented by simply modifying the loss function. <em>L₂ regularisation</em> (sometimes called ridge regression) adds to the loss a penalty proportional to <code>θ^2</code> for every scalar parameter. A very simple model could be implemented as follows:</p><pre><code class="language-julia hljs">grads = Flux.gradient(densemodel) do m
  result = m(input)
  penalty = sum(abs2, m.weight)/2 + sum(abs2, m.bias)/2
  my_loss(result, label) + 0.42f0 * penalty
end</code></pre><p>Accessing each individual parameter array by hand won&#39;t work well for large models. Instead, we can use <a href="../../../reference/destructure/#Optimisers.trainables"><code>Flux.trainables</code></a> to collect all of them, and then apply a function to each one, and sum the result:</p><pre><code class="language-julia hljs">pen_l2(x::AbstractArray) = sum(abs2, x)/2

grads = Flux.gradient(model) do m
  result = m(input)
  penalty = sum(pen_l2, Flux.trainables(m))
  my_loss(result, label) + 0.42f0 * penalty
end</code></pre><p>However, the gradient of this penalty term is very simple: It is proportional to the original weights. So there is a simpler way to implement exactly the same thing, by modifying the optimiser instead of the loss function. This is done by replacing this:</p><pre><code class="language-julia hljs">opt_state = Flux.setup(Adam(0.1), model)</code></pre><p>with this:</p><pre><code class="language-julia hljs">decay_opt_state = Flux.setup(OptimiserChain(WeightDecay(0.42), Adam(0.1)), model)</code></pre><p>Flux&#39;s optimisers are really modifications applied to the gradient before using it to update the parameters, and <a href="../../../reference/training/optimisers/#Optimisers.OptimiserChain"><code>OptimiserChain</code></a> applies two such modifications. The first, <a href="../../../reference/training/optimisers/#Optimisers.WeightDecay"><code>WeightDecay</code></a> adds <code>0.42</code> times the original parameter to the gradient, matching the gradient of the penalty above (with the same, unrealistically large, constant). After that, in either case, <a href="../../../reference/training/optimisers/#Optimisers.Adam"><code>Adam</code></a> computes the final update.</p><p>The same trick works for <em>L₁ regularisation</em> (also called Lasso), where the penalty is  <code>pen_l1(x::AbstractArray) = sum(abs, x)</code> instead. This is implemented by <code>SignDecay(0.42)</code>.</p><p>The same <code>OptimiserChain</code> mechanism can be used for other purposes, such as gradient clipping with <a href="../../../reference/training/optimisers/#Optimisers.ClipGrad"><code>ClipGrad</code></a> or <a href="../../../reference/training/optimisers/#Optimisers.ClipNorm"><code>ClipNorm</code></a>.</p><p>Besides L1 / L2 / weight decay, another common and quite different kind of regularisation is provided by the <a href="../../../reference/models/layers/#Flux.Dropout"><code>Dropout</code></a> layer. This turns off some outputs of the previous layer during training. It should switch automatically, but see <a href="../../../reference/models/layers/#Flux.trainmode!"><code>trainmode!</code></a> / <a href="../../../reference/models/layers/#Flux.testmode!"><code>testmode!</code></a> to manually enable or disable this layer.</p><h2 id="Learning-Rate-Schedules"><a class="docs-heading-anchor" href="#Learning-Rate-Schedules">Learning Rate Schedules</a><a id="Learning-Rate-Schedules-1"></a><a class="docs-heading-anchor-permalink" href="#Learning-Rate-Schedules" title="Permalink"></a></h2><p>Finer control of training, you may wish to alter the learning rate mid-way through training. This can be done with <a href="../../../reference/training/reference/#Optimisers.adjust!"><code>adjust!</code></a>, like this:</p><pre><code class="language-julia hljs">opt_state = Flux.setup(Adam(0.1), model)  # initialise once

for epoch in 1:1000
  train!([...], state)  # Train with η = 0.1 for first 100,
  if epoch == 100       # then change to use η = 0.01 for the rest.
    Flux.adjust!(opt_state, 0.01)
  end
end</code></pre><p>Other hyper-parameters can also be adjusted, such as <code>Flux.adjust!(opt_state, beta = (0.8, 0.99))</code>. And such modifications can be applied to just one part of the model. For instance, this sets a different learning rate for the encoder and the decoder:</p><pre><code class="language-julia hljs"># Consider some model with two parts:
bimodel = Chain(enc = [...], dec = [...])

# This returns a tree whose structure matches the model:
opt_state = Flux.setup(Adam(0.02), bimodel)

# Adjust the learning rate to be used for bimodel.layers.enc
Flux.adjust!(opt_state.layers.enc, 0.03)</code></pre><h2 id="Scheduling-Optimisers"><a class="docs-heading-anchor" href="#Scheduling-Optimisers">Scheduling Optimisers</a><a id="Scheduling-Optimisers-1"></a><a class="docs-heading-anchor-permalink" href="#Scheduling-Optimisers" title="Permalink"></a></h2><p>In practice, it is fairly common to schedule the learning rate of an optimiser to obtain faster convergence. There are a variety of popular scheduling policies, and you can find implementations of them in <a href="http://fluxml.ai/ParameterSchedulers.jl/stable">ParameterSchedulers.jl</a>. The documentation for ParameterSchedulers.jl provides a more detailed overview of the different scheduling policies, and how to use them with Flux optimisers. Below, we provide a brief snippet illustrating a <a href="https://arxiv.org/pdf/1608.03983.pdf">cosine annealing</a> schedule with a momentum optimiser.</p><p>First, we import ParameterSchedulers.jl and initialize a cosine annealing schedule to vary the learning rate between <code>1e-4</code> and <code>1e-2</code> every 10 epochs. We also create a new <a href="../../../reference/training/optimisers/#Optimisers.Momentum"><code>Momentum</code></a> optimiser.</p><pre><code class="language-julia hljs">using ParameterSchedulers

opt_state = Flux.setup(Momentum(), model)
schedule = Cos(λ0 = 1e-4, λ1 = 1e-2, period = 10)
for (eta, epoch) in zip(schedule, 1:100)
  Flux.adjust!(opt_state, eta)
  # your training code here
end</code></pre><p><code>schedule</code> can also be indexed (e.g. <code>schedule(100)</code>) or iterated like any iterator in Julia.</p><p>ParameterSchedulers.jl schedules are stateless (they don&#39;t store their iteration state). If you want a <em>stateful</em> schedule, you can use <code>ParameterSchedulers.Stateful</code>:</p><pre><code class="language-julia hljs">using ParameterSchedulers: Stateful, next!

schedule = Stateful(Cos(λ0 = 1e-4, λ1 = 1e-2, period = 10))
for epoch in 1:100
  Flux.adjust!(opt_state, next!(schedule))
  # your training code here
end</code></pre><p>Finally, a scheduling function can be incorporated into the optimser&#39;s state, advanced at each gradient update step, and possibly passed to the <code>train!</code> function. See <a href="https://fluxml.ai/ParameterSchedulers.jl/stable/tutorials/optimizers/#Working-with-Flux-optimizers">this section</a> of ParameterSchedulers.jl documentation for more details.</p><p>ParameterSchedulers.jl allows for many more scheduling policies including arbitrary functions, looping any function with a given period, or sequences of many schedules. See the <a href="https://fluxml.ai/ParameterSchedulers.jl/stable">ParameterSchedulers.jl documentation</a> for more info.</p><h2 id="Freezing-layer-parameters"><a class="docs-heading-anchor" href="#Freezing-layer-parameters">Freezing layer parameters</a><a id="Freezing-layer-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Freezing-layer-parameters" title="Permalink"></a></h2><p>To completely disable training of some part of the model, use <a href="../../../reference/training/reference/#Optimisers.freeze!"><code>freeze!</code></a>. This is a temporary modification, reversed by <code>thaw!</code>:</p><pre><code class="language-julia hljs">Flux.freeze!(opt_state.layers.enc)

# Now training won&#39;t update parameters in bimodel.layers.enc
train!(loss, bimodel, data, opt_state)

# Un-freeze the entire model:
Flux.thaw!(opt_state)</code></pre><p>While <code>adjust!</code> and <code>freeze!</code>/<code>thaw!</code> make temporary modifications to the optimiser state, permanently removing some fields of a new layer type from training is usually done when defining the layer, by calling for example <a href="../../../reference/models/functors/#Flux.@layer"><code>@layer</code></a><code>NewLayer trainable=(weight,)</code>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../models/basics/">« Gradients and Layers</a><a class="docs-footer-nextpage" href="../../models/recurrence/">Recurrence »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Thursday 6 February 2025 21:19">Thursday 6 February 2025</span>. Using Julia version 1.11.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
